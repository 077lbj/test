{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c5dfe-b9c3-4d10-a88c-fa94033e6ac7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-23T12:59:23.691656Z",
     "iopub.status.busy": "2024-12-23T12:59:23.691318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to die than to famish?\n",
      "\n",
      "all:\n",
      "resolved. resolved.\n",
      "\n",
      "first citizen:\n",
      "first, you know caius marcius is chief enemy to the people.\n",
      "\n",
      "all:\n",
      "we know't, we know't.\n",
      "\n",
      "first citizen:\n",
      "let us kill him, and we'll have corn at our own price.\n",
      "is't a verdict?\n",
      "\n",
      "all:\n",
      "no more talking on't; let it be done: away, away!\n",
      "\n",
      "second citizen:\n",
      "one word, good citizens.\n",
      "\n",
      "first citizen:\n",
      "we are accounted poor\n",
      "目标数据y形状: (11153, 100, 39)\n",
      "训练集 X 的形状: (8922, 100)\n",
      "验证集 X 的形状: (2231, 100)\n",
      "训练集 y 的形状: (8922, 100, 39)\n",
      "验证集 y 的形状: (2231, 100, 39)\n",
      "Epoch 1/50\n",
      "\u001b[1m29/70\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 4s/step - loss: 3.8224"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, LayerNormalization, MultiHeadAttention, Reshape\n",
    "\n",
    "# 下载莎士比亚文本数据（或者用你自己的数据集）\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "file_path = 'input.txt'\n",
    "if not os.path.exists(file_path):\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "\n",
    "# 读取文本数据并转为小写\n",
    "with open(file_path, 'r') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "# 打印文本前500个字符\n",
    "print(text[:500])\n",
    "\n",
    "# 创建字符到整数的映射\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_index = {char: index for index, char in enumerate(chars)}\n",
    "index_to_char = {index: char for index, char in enumerate(chars)}\n",
    "\n",
    "# 将文本转换为整数表示\n",
    "text_as_int = np.array([char_to_index[char] for char in text])\n",
    "\n",
    "# 创建训练数据（输入-目标对）\n",
    "seq_length = 100  # 输入序列长度\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(text_as_int) - seq_length, seq_length):\n",
    "    x_data.append(text_as_int[i:i + seq_length])\n",
    "    y_data.append(text_as_int[i + 1:i + seq_length + 1])  # 目标是下一个字符\n",
    "\n",
    "# 将数据转换为Numpy数组\n",
    "X = np.array(x_data)\n",
    "y = np.array(y_data)\n",
    "\n",
    "# 归一化输入数据\n",
    "X = X / float(len(chars))\n",
    "\n",
    "# 将目标数据进行 One-hot 编码\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(chars))\n",
    "\n",
    "# 检查y的形状\n",
    "print(f\"目标数据y形状: {y.shape}\")\n",
    "\n",
    "# 不需要对y进行squeeze操作，因为它已经是 (None, seq_length, num_classes) 形状\n",
    "\n",
    "# 分割训练集和验证集（80%训练，20%验证）\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# 打印数据形状\n",
    "print(f\"训练集 X 的形状: {X_train.shape}\")\n",
    "print(f\"验证集 X 的形状: {X_val.shape}\")\n",
    "print(f\"训练集 y 的形状: {y_train.shape}\")\n",
    "print(f\"验证集 y 的形状: {y_val.shape}\")\n",
    "\n",
    "\n",
    "# 定义 Transformer 模型\n",
    "def transformer_model(seq_length, num_features, num_classes):\n",
    "    inputs = Input(shape=(seq_length, num_features))  # (batch_size, seq_length, num_features)\n",
    "    \n",
    "    # Transformer架构的输入嵌入层\n",
    "    embedding = Embedding(input_dim=num_classes, output_dim=256)(inputs)  # 嵌入维度设置为256\n",
    "    \n",
    "    # 添加多头自注意力层\n",
    "    attention = MultiHeadAttention(num_heads=8, key_dim=256)(embedding, embedding)\n",
    "    attention = LayerNormalization()(attention)  # 归一化\n",
    "\n",
    "    # Feed-Forward 网络\n",
    "    ff = Dense(512, activation='relu')(attention)\n",
    "    ff = Dense(256)(ff)\n",
    "    ff = LayerNormalization()(ff)\n",
    "\n",
    "    # Dropout层\n",
    "    ff = Dropout(0.2)(ff)\n",
    "    \n",
    "    # 输出层（softmax 激活，用于分类）\n",
    "    output = Dense(num_classes, activation='softmax')(ff)\n",
    "    \n",
    "    # 移除额外维度，调整输出形状为 (None, 100, num_classes)\n",
    "    output = Reshape((seq_length, num_classes))(output)\n",
    "\n",
    "    # 构建并返回模型\n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# 模型参数\n",
    "num_classes = len(chars)  # 字符集大小\n",
    "num_features = 1  # 每个时间步的特征数（对于字符级文本，通常是1）\n",
    "seq_length = 100  # 输入序列长度\n",
    "\n",
    "# 创建 Transformer 模型\n",
    "model = transformer_model(seq_length, num_features, num_classes)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=50, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 文本生成函数\n",
    "def generate_text_transformer(model, seed_text, num_chars, temperature=1.0):\n",
    "    print(f\"生成文本种子: {seed_text}\")\n",
    "    \n",
    "    generated_text = seed_text\n",
    "    for _ in range(num_chars):\n",
    "        # 将种子文本转为数字\n",
    "        x_input = np.array([char_to_index[char] for char in seed_text])\n",
    "        x_input = x_input / float(len(chars))  # 归一化\n",
    "        x_input = np.reshape(x_input, (1, len(seed_text), 1))  # 重塑为Transformer输入形状\n",
    "\n",
    "        # 使用模型预测下一个字符的概率分布\n",
    "        predicted_prob = model.predict(x_input, verbose=0)\n",
    "        \n",
    "        # 温度控制：调整预测概率\n",
    "        predicted_prob = predicted_prob / temperature\n",
    "        \n",
    "        # 从概率分布中选择下一个字符的索引\n",
    "        predicted_index = np.random.choice(len(chars), p=predicted_prob[0])\n",
    "\n",
    "        # 将预测的字符添加到种子文本中\n",
    "        predicted_char = index_to_char[predicted_index]\n",
    "        generated_text += predicted_char\n",
    "\n",
    "        # 更新种子文本以便生成下一个字符\n",
    "        seed_text = seed_text[1:] + predicted_char\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# 生成文本\n",
    "seed_text = \"shall i compare thee to a summer's day\"\n",
    "generated_text = generate_text_transformer(model, seed_text, 500, temperature=1.0)\n",
    "\n",
    "# 输出生成的文本\n",
    "print(f\"\\n生成的文本:\\n{generated_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
